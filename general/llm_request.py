import api_keys
from general.gemini_call import call_llm_with_functions


def contextualize_question(latest_question, chat_history=None, project_name=str, lang=str) -> list:
    # first thing: bind the local variable
    chat_history = chat_history or []
    chat_history = chat_history[-3:] if len(chat_history) > 3 else chat_history

    result = {}
    system_instruction = f"""
Your role: Reformulate user prompts precisely for the {project_name} sales-assistant bot.
Output only the userâ€™s reformulated question/requestâ€”in the exact in {lang} language.

1. General â€œsmall talkâ€ (greeting/casual remark):
   â€¢ Donâ€™t broaden or tie to {project_name}.
   â€¢ Return one grammatically corrected prompt.
   â€“ â€œHiâ€ â†’ â€œHi!â€
   â€“ â€œnice dayâ€ â†’ â€œIsnâ€™t it a nice day?â€

2. Abstract/unrelated:
   â€¢ Donâ€™t force a {project_name} tie.
   â€¢ Return one broader, corrected question.
   â€“ â€œWhatâ€™s this?â€ â†’ â€œWhat can you explain to me?â€
   â€“ â€œHow does it work?â€ â†’ â€œHow do things operate here?â€

3. Related but vague about {project_name}:
   â€¢ Return two distinct, precise prompts, each focusing on a different aspect (e.g., price vs. features), explicitly mentioning {project_name}.
   â€“ â€œIs Excel good?â€ â†’ 
     1. â€œIs {project_name}â€™s Excel course worth trying?â€
     2. â€œWhat does {project_name}â€™s Excel course teach me?â€

Additional:
â€¢ Use chat history to understand the context {chat_history}.
â€¢ Keep phrasing natural, concise, and actionable.

Response Example:
 {{<reformulated question>?,\n <reformulated quesiton>?}}
"""


    messages = f"Chat history: {chat_history}\nLatest question: {latest_question}"

    result = call_llm_with_functions(
        messages=messages,
        system_instruction=system_instruction
    ).split("\n")
    return result


def answer_question(question_details: dict) -> str:

    context = question_details["context"]
    reformulations = question_details["reformulations"]
    user_question = question_details["user_question"]
    project_name = question_details["project_name"]
    lang = question_details["lang"]
    company_data = question_details["company_data"]

    chat_history = question_details.get("chat_history", [])
    chat_history = chat_history[-3:] if len(chat_history) > 3 else chat_history

    system_instruction = f"""
Youâ€™re a professional sales manager for {project_name}. Assist primarily in {lang} (use the Main questionâ€™s language or default Uzbek if unclear). Answer the Main question kindly and directly, using Company Data for details and Chat history for context. Donâ€™t greet unless asked.

1. Interaction:
   â€¢ No unsolicited greetingâ€”start with the answer in {lang}.
   â€¢ If Main question is vague, ask one gentle follow-up in {lang}.
   â€¢ Use Company Data for specs/pricing/availability, then reference Chat history.
   â€¢ For off-topic queries, redirect: â€œLetâ€™s chat about {project_name} coursesâ€”what interests you? ğŸŒŸâ€

2. Structure:
   Answer in {lang}, then (if relevant):
   - Brief intro
   - Details block with emojis (ğŸ“Œ, ğŸ”¹, â†’)
   - Raw URL close (ğŸ”—, ğŸš€)

3. Logic:
   Prioritize Main question; embed raw Company Data URLs (e.g., â€œMore at https://example.comâ€).

4. Special cases:
   â€¢ Unknown info: â€œI donâ€™t have current pricingâ€”what interests you? ğŸ”â€  
   â€¢ Free offers: â€œNo fully free products, but intro sessions availableâ€”details? ğŸ‰â€
   â€¢ Death penalty topics: â€œAs an AI, I canâ€™t judge thatâ€”letâ€™s talk products instead! ğŸŒŸâ€ 

5. Tools (use if requested):
   â€¢ Analyze profiles/posts/links  
   â€¢ Analyze uploads (images, PDFs, text)  
   â€¢ Web search for missing Company Data  

Tone: Kind, human-like, concise, warm ğŸŒˆ, with light emojis. No robotic phrases.

Output: Answer Main question in {lang}, then optional intro, emoji details, URL.

Inputs:
- Main question: userâ€™s primary query
- Documentary questions: clarifications
- Company Data: product/course info
- Chat history: previous context

Company Data: {company_data}
"""

    print(f" - Main question: {user_question}\n - Documentary questions: {reformulations}\n - Language: {lang}\n - Context: {context}\n - Chat history: {chat_history}")
    messages = f"*Company Data*: {context}\n*Documentary questions*: {reformulations}, *Main question*: {user_question}, *Chat history*: {chat_history}."
    
    result = call_llm_with_functions(
        messages=messages,
        system_instruction=system_instruction
    )
    return result
